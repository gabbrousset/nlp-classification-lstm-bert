{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "41d2db05-2f8f-4935-bb1b-c98ffe8bcd1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "\n",
    "# Anti-Grain Geometry: Essential for clusters without screens (X11 forwarding)\n",
    "matplotlib.use('Agg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "37449d40-f259-47c5-90d8-c8214b6d96f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset, random_split, Subset\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, BertModel, get_linear_schedule_with_warmup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6288f056-bce8-49f9-b6c3-f6826db6881f",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 551\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# Cluster Optimization: Determine workers based on CPU count, capped at 4 for safety\n",
    "NUM_WORKERS = min(4, os.cpu_count() if os.cpu_count() else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2394e1d8-c611-4893-93b8-8df447c18856",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDevice():\n",
    "    device = \"cpu\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda\"\n",
    "    elif torch.backends.mps.is_available():\n",
    "        device = torch.device(\"mps\")\n",
    "\n",
    "    print(f\"Using device: {device}\")\n",
    "    return device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46168ff5-782e-478c-9420-a5f631efce18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "DEVICE = getDevice()\n",
    "PIN_MEMORY = True if str(DEVICE) == \"cuda\" else False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24db1964-ab7d-4518-ab3f-5f0267629046",
   "metadata": {},
   "source": [
    "## Task 1: Acquire and Pre-process the Web of Science Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d689594-cf48-4465-97da-136ec6a3ab10",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"WebOfScienceDataset/WOS11967\"\n",
    "GLOVE_PATH = \"glove.6B/glove.6B.300d.txt\"\n",
    "\n",
    "MAX_SEQ_LEN = 200\n",
    "EMBED_DIM = 300\n",
    "MAX_VOCAB = 10000\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee33bf46-7882-4b81-9f1c-9d276f9b4351",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-z0-9 ]', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "def load_data(data_dir):\n",
    "    with open(os.path.join(data_dir, 'X.txt'), 'r', encoding='utf-8') as f:\n",
    "        texts = [clean_text(line) for line in f.readlines()]\n",
    "\n",
    "    with open(os.path.join(data_dir, 'Y.txt'), 'r', encoding='utf-8') as f:\n",
    "        y_sub = [int(line.strip()) for line in f.readlines()]\n",
    "\n",
    "    with open(os.path.join(data_dir, 'YL1.txt'), 'r', encoding='utf-8') as f:\n",
    "        y_domain = [int(line.strip()) for line in f.readlines()]\n",
    "\n",
    "    return texts, y_sub, y_domain\n",
    "\n",
    "\n",
    "def get_dynamic_max_len(texts, percentile=95):\n",
    "    lengths = [len(t.split()) for t in texts]\n",
    "    limit = int(np.percentile(lengths, percentile))\n",
    "    print(f\"95th percentile length is {limit}. Mean is {int(np.mean(lengths))}.\")\n",
    "    return limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a315a8b8-c780-4636-b059-081dbe60e9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocab(texts, max_words=MAX_VOCAB, min_freq=2):\n",
    "    word_counts = Counter()\n",
    "    for text in texts:\n",
    "        word_counts.update(text.split())\n",
    "\n",
    "    vocab = {\"<PAD>\": 0, \"<UNK>\": 1}\n",
    "\n",
    "    for word, count in word_counts.most_common(max_words - 2):\n",
    "        if count >= min_freq:\n",
    "            vocab[word] = len(vocab)\n",
    "\n",
    "    return vocab\n",
    "\n",
    "\n",
    "def encode_texts(texts, vocab, max_len=MAX_SEQ_LEN):\n",
    "    tensor_data = []\n",
    "    unk_idx = vocab[\"<UNK>\"]\n",
    "    pad_idx = vocab[\"<PAD>\"]\n",
    "\n",
    "    for text in texts:\n",
    "        tokens = text.split()\n",
    "        seq = [vocab.get(t, unk_idx) for t in tokens]\n",
    "\n",
    "        if len(seq) < max_len:\n",
    "            seq = seq + [pad_idx] * (max_len - len(seq))\n",
    "        else:\n",
    "            seq = seq[:max_len]\n",
    "\n",
    "        tensor_data.append(seq)\n",
    "\n",
    "    return torch.tensor(tensor_data, dtype=torch.long)\n",
    "\n",
    "\n",
    "def load_glove_matrix(path, vocab, embed_dim=EMBED_DIM):\n",
    "    weights = np.random.uniform(-0.25, 0.25, (len(vocab), embed_dim))\n",
    "\n",
    "    if \"<PAD>\" in vocab:\n",
    "        weights[vocab[\"<PAD>\"]] = 0\n",
    "\n",
    "    hits = 0\n",
    "    # Optimization: Using a set for O(1) lookups\n",
    "    vocab_set = set(vocab.keys())\n",
    "\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "\n",
    "            if word in vocab_set:\n",
    "                vector = np.array(values[1:], dtype=float)\n",
    "                if len(vector) == embed_dim:\n",
    "                    weights[vocab[word]] = vector\n",
    "                    hits += 1\n",
    "\n",
    "    print(f\"GloVe loaded. Found {hits} / {len(vocab)} words.\")\n",
    "    return torch.tensor(weights, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e864665-308a-41ef-b2f9-41880fce0fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data():\n",
    "    texts, y_sub, y_domain = load_data(DATA_DIR)\n",
    "    dynamic_max_len = get_dynamic_max_len(texts)\n",
    "    vocab = build_vocab(texts)\n",
    "\n",
    "    X_tensor = encode_texts(texts, vocab, max_len=dynamic_max_len)\n",
    "    Y_sub_tensor = torch.tensor(y_sub, dtype=torch.long)\n",
    "    Y_domain_tensor = torch.tensor(y_domain, dtype=torch.long)\n",
    "    embedding_weights = load_glove_matrix(GLOVE_PATH, vocab)\n",
    "\n",
    "    dataset = TensorDataset(X_tensor, Y_domain_tensor, Y_sub_tensor)\n",
    "\n",
    "    test_size = int(0.2 * len(dataset))\n",
    "    remaining_size = len(dataset) - test_size\n",
    "    val_size = int(0.2 * remaining_size)\n",
    "    train_size = remaining_size - val_size\n",
    "\n",
    "    train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "    # Cluster Optimization: workers and pinning\n",
    "    train_ldr = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS,\n",
    "                           pin_memory=PIN_MEMORY)\n",
    "    val_ldr = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS,\n",
    "                         pin_memory=PIN_MEMORY)\n",
    "    test_ldr = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS,\n",
    "                          pin_memory=PIN_MEMORY)\n",
    "\n",
    "    return train_ldr, val_ldr, test_ldr, embedding_weights, vocab, train_dataset, val_dataset, test_dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b256077-acae-4d8b-b8df-2a008f5bef39",
   "metadata": {},
   "source": [
    "## Task 2: Implement LSTM and BERT models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8466311c-b3f9-443f-887e-d575768e14c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLSTMCell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, init_type):\n",
    "        super(CustomLSTMCell, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.weight_ih = nn.Linear(input_size, 4 * hidden_size)\n",
    "        self.weight_hh = nn.Linear(hidden_size, 4 * hidden_size)\n",
    "\n",
    "        if init_type == 'xavier':\n",
    "            nn.init.xavier_uniform_(self.weight_ih.weight)\n",
    "            nn.init.xavier_uniform_(self.weight_hh.weight)\n",
    "        elif init_type == 'zero':\n",
    "            nn.init.zeros_(self.weight_ih.weight)\n",
    "            nn.init.zeros_(self.weight_hh.weight)\n",
    "        elif init_type == 'random':\n",
    "            nn.init.normal_(self.weight_ih.weight, mean=0, std=0.01)\n",
    "            nn.init.normal_(self.weight_hh.weight, mean=0, std=0.01)\n",
    "\n",
    "    def forward(self, x, state):\n",
    "        # type: (Tensor, Tuple[Tensor, Tensor]) -> Tuple[Tensor, Tensor]\n",
    "        h_prev, c_prev = state\n",
    "        gates = self.weight_ih(x) + self.weight_hh(h_prev)\n",
    "        i_gate, f_gate, g_gate, o_gate = gates.chunk(4, 1)\n",
    "\n",
    "        i = torch.sigmoid(i_gate)\n",
    "        f = torch.sigmoid(f_gate)\n",
    "        g = torch.tanh(g_gate)\n",
    "        o = torch.sigmoid(o_gate)\n",
    "\n",
    "        c_next = (f * c_prev) + (i * g)\n",
    "        h_next = o * torch.tanh(c_next)\n",
    "\n",
    "        return h_next, c_next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e46712d6-6868-42be-ad98-d94006564e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JittedLSTMLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    Wraps the cell and the loop so the ENTIRE loop is compiled to C++.\n",
    "    This eliminates the Python interpreter overhead during the sequence loop.\n",
    "    \"\"\"\n",
    "    def __init__(self, cell):\n",
    "        super().__init__()\n",
    "        self.cell = cell\n",
    "\n",
    "    def forward(self, x_emb):\n",
    "        # type: (Tensor) -> Tensor\n",
    "        # We must explicitly type inputs for JIT to work\n",
    "        batch_size = x_emb.size(0)\n",
    "        seq_len = x_emb.size(1)\n",
    "\n",
    "        # Initialize states on the correct device\n",
    "        h_t = torch.zeros(batch_size, self.cell.hidden_size, device=x_emb.device)\n",
    "        c_t = torch.zeros(batch_size, self.cell.hidden_size, device=x_emb.device)\n",
    "\n",
    "        # This loop now runs in C++!\n",
    "        for t in range(seq_len):\n",
    "            x_t = x_emb[:, t, :]\n",
    "            h_t, c_t = self.cell(x_t, (h_t, c_t))\n",
    "            \n",
    "        return h_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2177890c-6ec7-488f-b9af-e210571880d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimization: JIT Script compiles this class to C++, speeding up the manual loop significantly\n",
    "class CustomLSTMModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, output_dim, hidden_size=512, embedding_matrix=None, dropout=0.5, init_type='xavier'):\n",
    "        super(CustomLSTMModel, self).__init__()\n",
    "        self.device = getDevice()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
    "        if embedding_matrix is not None:\n",
    "            self.embedding.weight = nn.Parameter(embedding_matrix)\n",
    "\n",
    "        cell = CustomLSTMCell(embed_dim, hidden_size, init_type)\n",
    "        self.lstm_layer = torch.jit.script(JittedLSTMLayer(cell))\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(hidden_size, output_dim)\n",
    "        self.to(self.device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Embed\n",
    "        x_emb = self.embedding(x)\n",
    "        \n",
    "        # Fast C++ Loop\n",
    "        h_t = self.lstm_layer(x_emb)\n",
    "\n",
    "        # Classify\n",
    "        out = self.dropout(h_t)\n",
    "        logits = self.fc(out)\n",
    "        return logits\n",
    "\n",
    "    def fit(self, train_ldr, val_ldr, epochs=10, lr=0.001, l1_lambda=0.0, weight_decay=0.0):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        history = {\"train_loss\": [], \"val_loss\": [], \"val_acc\": []}\n",
    "        print(f\"\\ntraining LSTM (output dim: {self.output_dim}) for {epochs} epochs\")\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            self.train()\n",
    "            total_loss = 0\n",
    "\n",
    "            for X_batch, Y_domain, Y_sub in train_ldr:\n",
    "                X_batch = X_batch.to(self.device)\n",
    "                target = Y_domain.to(self.device) if self.output_dim == 7 else Y_sub.to(self.device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                outputs = self(X_batch)\n",
    "                loss = criterion(outputs, target)\n",
    "\n",
    "                if l1_lambda > 0:\n",
    "                    l1_norm = sum(p.abs().sum() for p in self.parameters())\n",
    "                    loss += l1_lambda * l1_norm\n",
    "\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(self.parameters(), 1.0)\n",
    "                optimizer.step()\n",
    "                total_loss += loss.item()\n",
    "\n",
    "            val_acc = self.evaluate_acc(val_ldr)\n",
    "            val_loss = self.evaluate_loss(val_ldr, criterion)\n",
    "\n",
    "            history[\"val_acc\"].append(val_acc)\n",
    "            history[\"val_loss\"].append(val_loss)\n",
    "            print(f\"epoch {epoch + 1}/{epochs} | loss: {total_loss / len(train_ldr):.4f} | val acc: {val_acc:.2f}%\")\n",
    "\n",
    "        return history\n",
    "\n",
    "    def predict(self, X):\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            X = X.to(self.device)\n",
    "            outputs = self(X)\n",
    "            predictions = torch.argmax(outputs, dim=1)\n",
    "        return predictions\n",
    "\n",
    "    def evaluate_acc(self, data_loader):\n",
    "        self.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for X_batch, Y_domain, Y_sub in data_loader:\n",
    "                X_batch = X_batch.to(self.device)\n",
    "                target = Y_domain.to(self.device) if self.output_dim == 7 else Y_sub.to(self.device)\n",
    "                preds = self.predict(X_batch)\n",
    "                correct += (preds == target).sum().item()\n",
    "                total += target.size(0)\n",
    "        return 100 * correct / total\n",
    "\n",
    "    def evaluate_loss(self, data_loader, criterion):\n",
    "        self.eval()\n",
    "        total_loss = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for X_batch, Y_domain, Y_sub in data_loader:\n",
    "                X_batch = X_batch.to(self.device)\n",
    "                target = Y_domain.to(self.device) if self.output_dim == 7 else Y_sub.to(self.device)\n",
    "                outputs = self(X_batch)\n",
    "                loss = criterion(outputs, target)\n",
    "                total_loss += loss.item() * target.size(0)\n",
    "                total += target.size(0)\n",
    "        return total_loss / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b126e06-3372-4255-aff0-5dc7baa03369",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTClassifier(nn.Module):\n",
    "    def __init__(self, output_dim, model_name='bert-base-uncased', dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.device = getDevice()\n",
    "        self.bert = BertModel.from_pretrained(model_name, output_attentions=True)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(self.bert.config.hidden_size, output_dim)\n",
    "        self.to(self.device)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooler_output = outputs.pooler_output\n",
    "        pooled_output = self.dropout(pooler_output)\n",
    "        logits = self.fc(pooled_output)\n",
    "        return logits\n",
    "\n",
    "    def get_attention_maps(self, input_ids, attention_mask):\n",
    "        with torch.no_grad():\n",
    "            outputs = self.bert(input_ids=input_ids.to(self.device),\n",
    "                                attention_mask=attention_mask.to(self.device))\n",
    "        return outputs.attentions\n",
    "\n",
    "    def fit(self, train_ldr, val_ldr, lr=2e-5, epochs=3, patience=2, weight_decay=0.0, l1_lambda=0.0):\n",
    "        optimizer = optim.AdamW(self.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "        total_steps = len(train_ldr) * epochs\n",
    "        scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        history = {\"val_acc\": []}\n",
    "        best_val_loss = float('inf')\n",
    "        patience_counter = 0\n",
    "\n",
    "        print(f\"starting BERT fine-tuning\")\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            self.train()\n",
    "            total_train_loss = 0\n",
    "            correct_train = 0\n",
    "            total_samples = 0\n",
    "            start_time = time.time()\n",
    "\n",
    "            for batch in train_ldr:\n",
    "                b_input_ids = batch[0].to(self.device)\n",
    "                b_input_mask = batch[1].to(self.device)\n",
    "                b_labels = batch[2].to(self.device)\n",
    "\n",
    "                self.zero_grad()\n",
    "                logits = self.forward(b_input_ids, b_input_mask)\n",
    "                loss = criterion(logits, b_labels)\n",
    "\n",
    "                if l1_lambda > 0:\n",
    "                    l1_norm = sum(p.abs().sum() for p in self.parameters())\n",
    "                    loss += l1_lambda * l1_norm\n",
    "\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(self.parameters(), 1.0)\n",
    "                optimizer.step()\n",
    "                scheduler.step()\n",
    "\n",
    "                total_train_loss += loss.item() * b_input_ids.size(0)\n",
    "                preds = torch.argmax(logits, dim=1)\n",
    "                correct_train += (preds == b_labels).sum().item()\n",
    "                total_samples += b_input_ids.size(0)\n",
    "\n",
    "            avg_train_loss = total_train_loss / total_samples\n",
    "            train_acc = correct_train / total_samples\n",
    "            val_loss, val_acc = self.evaluate(val_ldr, criterion)\n",
    "\n",
    "            epoch_time = time.time() - start_time\n",
    "            print(\n",
    "                f\"epoch {epoch + 1}/{epochs} [{epoch_time:.1f}s] | train loss: {avg_train_loss:.4f} acc: {train_acc:.4f} | val loss: {val_loss:.4f} acc: {val_acc:.4f}\")\n",
    "\n",
    "            history[\"val_acc\"].append(val_acc)\n",
    "\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                torch.save(self.state_dict(), \"best_bert_model.pth\")\n",
    "                patience_counter = 0\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "                if patience_counter >= patience:\n",
    "                    print(\"Early stopping triggered.\")\n",
    "                    break\n",
    "\n",
    "        self.load_state_dict(torch.load(\"best_bert_model.pth\"))\n",
    "        return history\n",
    "\n",
    "    def evaluate(self, val_ldr, criterion):\n",
    "        self.eval()\n",
    "        total_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for batch in val_ldr:\n",
    "                b_input_ids = batch[0].to(self.device)\n",
    "                b_input_mask = batch[1].to(self.device)\n",
    "                b_labels = batch[2].to(self.device)\n",
    "\n",
    "                logits = self.forward(b_input_ids, b_input_mask)\n",
    "                loss = criterion(logits, b_labels)\n",
    "\n",
    "                total_loss += loss.item() * b_input_ids.size(0)\n",
    "                preds = torch.argmax(logits, dim=1)\n",
    "                correct += (preds == b_labels).sum().item()\n",
    "                total += b_input_ids.size(0)\n",
    "\n",
    "        return total_loss / total, correct / total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f57032-b845-495a-8a54-0dc57afb8ba0",
   "metadata": {},
   "source": [
    "## Task 3: Run experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b16a99b7-555e-4c69-8b36-1f225bfb41c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_lstm(train_ds, val_ds, vocab_size, output_dim, batch_size=BATCH_SIZE, embedding_matrix=None, epochs=10,\n",
    "                  hidden_size=512, dropout=0.5, l1_lambda=0.0, weight_decay=0.0, lr=0.001, init_type='xavier'):\n",
    "    # Optim: Workers and pinning\n",
    "    train_ldr = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=NUM_WORKERS,\n",
    "                           pin_memory=PIN_MEMORY)\n",
    "    val_ldr = DataLoader(val_ds, batch_size=batch_size, shuffle=False, num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY)\n",
    "\n",
    "    model = CustomLSTMModel(vocab_size, embedding_matrix.shape[1], output_dim, hidden_size=hidden_size, dropout=dropout,\n",
    "                            embedding_matrix=embedding_matrix, init_type=init_type)\n",
    "\n",
    "    history = model.fit(train_ldr, val_ldr, lr=lr, epochs=epochs, l1_lambda=l1_lambda, weight_decay=weight_decay)\n",
    "    return max(history.get(\"val_acc\", [0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "580aceee-922f-4e2a-af3c-609036976e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bert_test_data(all_texts, all_labels, test_indices, max_length=256):\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "    test_texts = [all_texts[i] for i in test_indices]\n",
    "    test_labels = [all_labels[i] for i in test_indices]\n",
    "\n",
    "    test_encodings = tokenizer(test_texts, truncation=True, padding=True, max_length=max_length, return_tensors='pt')\n",
    "    test_dataset = TensorDataset(test_encodings['input_ids'], test_encodings['attention_mask'],\n",
    "                                 torch.tensor(test_labels))\n",
    "    # Optim: Workers and pinning\n",
    "    test_ldr = DataLoader(test_dataset, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY)\n",
    "    return test_ldr, test_texts, test_labels, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "909d9fc2-4e22-4779-9cc8-87745dc35987",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_combined_results(values, model_1_scores, model_2_scores, title, xlabel, label_model_1=\"LSTM Val Acc\",\n",
    "                          label_model_2=\"BERT Val Acc\", save_dir=\"plots\"):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(values, model_1_scores, label=label_model_1, marker='o')\n",
    "    ax.plot(values, model_2_scores, label=label_model_2, marker='x')\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel(\"Validation Accuracy\")\n",
    "    ax.set_title(title)\n",
    "    ax.legend()\n",
    "    ax.grid(True)\n",
    "\n",
    "    clean_title = title.replace(\" \", \"_\").replace(\":\", \"\")\n",
    "    filename = f\"{clean_title}.png\"\n",
    "    filepath = os.path.join(save_dir, filename)\n",
    "    fig.savefig(filepath, bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "    print(f\"saved plot to: {filepath}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "50337160-5e50-4ee3-99c2-0901fd1632c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_single_result(values, scores, title, xlabel, ylabel=\"Validation Accuracy\", save_dir=\"plots\"):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    ax.plot(values, scores, marker='o', label='LSTM')\n",
    "\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.set_title(title)\n",
    "    ax.legend()\n",
    "    ax.grid(True)\n",
    "\n",
    "    clean_title = title.replace(\" \", \"_\").replace(\":\", \"\")\n",
    "    filename = f\"{clean_title}.png\"\n",
    "    filepath = os.path.join(save_dir, filename)\n",
    "\n",
    "    fig.savefig(filepath, bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "    print(f\"saved plot to: {filepath}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c3375fc3-5abc-4530-b572-e8b4c0d352a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data\n",
      "95th percentile length is 333. Mean is 201.\n",
      "GloVe loaded. Found 9853 / 10000 words.\n"
     ]
    }
   ],
   "source": [
    "print(\"loading data\")\n",
    "train_loader, val_loader, test_loader, embedding_matrix, vocab, train_ds, val_ds, test_ds = prepare_data()\n",
    "\n",
    "# reload raw texts for BERT\n",
    "all_texts, y_sub_raw, y_domain_raw = load_data(DATA_DIR)\n",
    "\n",
    "vocab_size = len(vocab)\n",
    "output_dim_domain = 7\n",
    "output_dim_sub = 33\n",
    "\n",
    "train_indices = train_ds.indices\n",
    "val_indices = val_ds.indices\n",
    "test_indices = test_ds.indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "73a8ca39-d0d2-44e5-bc52-a4d26b2a0b8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing BERT data...\n"
     ]
    }
   ],
   "source": [
    "# Pre-tokenize BERT inputs once to save time in loops\n",
    "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert_train_texts = [all_texts[i] for i in train_indices]\n",
    "bert_val_texts = [all_texts[i] for i in val_indices]\n",
    "\n",
    "print(\"Tokenizing BERT data...\")\n",
    "bert_train_enc = bert_tokenizer(bert_train_texts, truncation=True, padding=True, max_length=256, return_tensors='pt')\n",
    "bert_val_enc = bert_tokenizer(bert_val_texts, truncation=True, padding=True, max_length=256, return_tensors='pt')\n",
    "\n",
    "bert_sub_train_labels = torch.tensor([y_sub_raw[i] for i in train_indices])\n",
    "bert_sub_val_labels = torch.tensor([y_sub_raw[i] for i in val_indices])\n",
    "bert_domain_train_labels = torch.tensor([y_domain_raw[i] for i in train_indices])\n",
    "bert_domain_val_labels = torch.tensor([y_domain_raw[i] for i in val_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a08f9fe9-f0ae-4233-9836-d4f607b5ead7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing dropout: 0.5\n",
      "Using device: cuda\n",
      "\n",
      "training LSTM (output dim: 7) for 10 epochs\n",
      "epoch 1/10 | loss: 1.9308 | val acc: 17.19%\n",
      "epoch 2/10 | loss: 1.7173 | val acc: 29.47%\n",
      "epoch 3/10 | loss: 1.9004 | val acc: 23.51%\n",
      "epoch 4/10 | loss: 1.8514 | val acc: 26.70%\n",
      "epoch 5/10 | loss: 1.6863 | val acc: 28.06%\n",
      "epoch 6/10 | loss: 1.6920 | val acc: 29.41%\n",
      "epoch 7/10 | loss: 1.3997 | val acc: 51.83%\n",
      "epoch 8/10 | loss: 0.9659 | val acc: 73.41%\n",
      "epoch 9/10 | loss: 0.7064 | val acc: 78.94%\n",
      "epoch 10/10 | loss: 0.4460 | val acc: 84.54%\n",
      "Using device: cuda\n",
      "\n",
      "training LSTM (output dim: 33) for 20 epochs\n",
      "epoch 1/20 | loss: 3.4918 | val acc: 3.40%\n",
      "epoch 2/20 | loss: 3.4725 | val acc: 3.45%\n",
      "epoch 3/20 | loss: 3.3910 | val acc: 2.93%\n",
      "epoch 4/20 | loss: 3.4797 | val acc: 5.49%\n",
      "epoch 5/20 | loss: 3.1792 | val acc: 7.89%\n",
      "epoch 6/20 | loss: 2.9105 | val acc: 9.72%\n",
      "epoch 7/20 | loss: 2.7374 | val acc: 10.76%\n",
      "epoch 8/20 | loss: 2.5957 | val acc: 12.75%\n",
      "epoch 9/20 | loss: 2.4416 | val acc: 16.14%\n",
      "epoch 10/20 | loss: 2.1570 | val acc: 23.72%\n",
      "epoch 11/20 | loss: 1.9641 | val acc: 27.01%\n",
      "epoch 12/20 | loss: 1.8115 | val acc: 32.39%\n",
      "epoch 13/20 | loss: 1.6221 | val acc: 39.03%\n",
      "epoch 14/20 | loss: 1.4203 | val acc: 45.40%\n",
      "epoch 15/20 | loss: 1.1973 | val acc: 50.16%\n",
      "epoch 16/20 | loss: 0.9915 | val acc: 56.27%\n",
      "epoch 17/20 | loss: 0.8817 | val acc: 55.17%\n",
      "epoch 18/20 | loss: 0.7789 | val acc: 60.24%\n",
      "epoch 19/20 | loss: 0.7019 | val acc: 62.17%\n",
      "epoch 20/20 | loss: 0.5834 | val acc: 64.26%\n",
      "testing dropout: 0.1\n",
      "Using device: cuda\n",
      "\n",
      "training LSTM (output dim: 7) for 10 epochs\n",
      "epoch 1/10 | loss: 1.9541 | val acc: 16.46%\n",
      "epoch 2/10 | loss: 1.9229 | val acc: 16.25%\n",
      "epoch 3/10 | loss: 1.8530 | val acc: 13.90%\n",
      "epoch 4/10 | loss: 1.9207 | val acc: 17.55%\n",
      "epoch 5/10 | loss: 1.4583 | val acc: 51.10%\n",
      "epoch 6/10 | loss: 0.8307 | val acc: 78.84%\n",
      "epoch 7/10 | loss: 0.4483 | val acc: 84.01%\n",
      "epoch 8/10 | loss: 0.2487 | val acc: 88.51%\n",
      "epoch 9/10 | loss: 0.1392 | val acc: 88.61%\n",
      "epoch 10/10 | loss: 0.0803 | val acc: 87.57%\n",
      "Using device: cuda\n",
      "\n",
      "training LSTM (output dim: 33) for 20 epochs\n",
      "epoch 1/20 | loss: 3.4923 | val acc: 3.61%\n",
      "epoch 2/20 | loss: 3.4642 | val acc: 3.66%\n",
      "epoch 3/20 | loss: 3.5184 | val acc: 3.03%\n",
      "epoch 4/20 | loss: 3.1262 | val acc: 11.70%\n",
      "epoch 5/20 | loss: 2.6695 | val acc: 13.90%\n",
      "epoch 6/20 | loss: 2.5177 | val acc: 17.87%\n",
      "epoch 7/20 | loss: 2.2276 | val acc: 23.77%\n",
      "epoch 8/20 | loss: 1.9280 | val acc: 32.45%\n",
      "epoch 9/20 | loss: 1.6836 | val acc: 40.75%\n",
      "epoch 10/20 | loss: 1.3708 | val acc: 49.27%\n",
      "epoch 11/20 | loss: 1.1115 | val acc: 56.74%\n",
      "epoch 12/20 | loss: 0.8508 | val acc: 57.52%\n",
      "epoch 13/20 | loss: 0.6716 | val acc: 66.67%\n",
      "epoch 14/20 | loss: 0.5471 | val acc: 63.95%\n",
      "epoch 15/20 | loss: 0.4284 | val acc: 68.81%\n",
      "epoch 16/20 | loss: 0.3643 | val acc: 72.94%\n",
      "epoch 17/20 | loss: 0.3098 | val acc: 70.90%\n",
      "epoch 18/20 | loss: 0.2537 | val acc: 71.32%\n",
      "epoch 19/20 | loss: 0.2153 | val acc: 72.83%\n",
      "epoch 20/20 | loss: 0.1923 | val acc: 72.94%\n",
      "saved plot to: plots/Effect_of_Dropout.png\n"
     ]
    }
   ],
   "source": [
    "# 1) test dropout\n",
    "dropout_list = [0.5, 0.1]\n",
    "lstm_res_domain = []\n",
    "lstm_res_sub = []\n",
    "\n",
    "for d in dropout_list:\n",
    "    print(f\"testing dropout: {d}\")\n",
    "    lstm_res_domain.append(\n",
    "        evaluate_lstm(train_ds, val_ds, vocab_size, output_dim_domain, embedding_matrix=embedding_matrix, dropout=d))\n",
    "    lstm_res_sub.append(\n",
    "        evaluate_lstm(train_ds, val_ds, vocab_size, output_dim_sub, embedding_matrix=embedding_matrix, dropout=d,\n",
    "                      epochs=20))\n",
    "\n",
    "plot_combined_results(dropout_list, lstm_res_domain, lstm_res_sub, \"Effect of Dropout\", \"Dropout Rate\")\n",
    "\n",
    "BEST_DROPOUT_LSTM_DOMAIN = dropout_list[np.argmax(lstm_res_domain)]\n",
    "BEST_DROPOUT_LSTM_SUB = dropout_list[np.argmax(lstm_res_sub)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1f8842a9-e9c5-47a4-bda1-4461c1edc0b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing learning rate: 0.001\n",
      "Using device: cuda\n",
      "\n",
      "training LSTM (output dim: 7) for 10 epochs\n",
      "epoch 1/10 | loss: 1.9401 | val acc: 18.13%\n",
      "epoch 2/10 | loss: 1.9555 | val acc: 18.50%\n",
      "epoch 3/10 | loss: 1.7543 | val acc: 27.85%\n",
      "epoch 4/10 | loss: 1.5714 | val acc: 34.80%\n",
      "epoch 5/10 | loss: 1.3190 | val acc: 54.13%\n",
      "epoch 6/10 | loss: 0.9941 | val acc: 68.03%\n",
      "epoch 7/10 | loss: 0.6345 | val acc: 77.90%\n",
      "epoch 8/10 | loss: 0.3339 | val acc: 83.86%\n",
      "epoch 9/10 | loss: 0.2041 | val acc: 88.14%\n",
      "epoch 10/10 | loss: 0.1299 | val acc: 89.18%\n",
      "Using device: cuda\n",
      "\n",
      "training LSTM (output dim: 33) for 20 epochs\n",
      "epoch 1/20 | loss: 3.4899 | val acc: 4.44%\n",
      "epoch 2/20 | loss: 3.4681 | val acc: 3.76%\n",
      "epoch 3/20 | loss: 3.4197 | val acc: 5.54%\n",
      "epoch 4/20 | loss: 3.3842 | val acc: 5.80%\n",
      "epoch 5/20 | loss: 3.3866 | val acc: 4.49%\n",
      "epoch 6/20 | loss: 3.2220 | val acc: 5.07%\n",
      "epoch 7/20 | loss: 2.9917 | val acc: 7.78%\n",
      "epoch 8/20 | loss: 2.9477 | val acc: 11.39%\n",
      "epoch 9/20 | loss: 2.8991 | val acc: 8.36%\n",
      "epoch 10/20 | loss: 2.8320 | val acc: 9.51%\n",
      "epoch 11/20 | loss: 2.7779 | val acc: 11.34%\n",
      "epoch 12/20 | loss: 2.5859 | val acc: 15.57%\n",
      "epoch 13/20 | loss: 2.3818 | val acc: 21.53%\n",
      "epoch 14/20 | loss: 2.0324 | val acc: 31.24%\n",
      "epoch 15/20 | loss: 1.7979 | val acc: 33.02%\n",
      "epoch 16/20 | loss: 1.5876 | val acc: 41.43%\n",
      "epoch 17/20 | loss: 1.4381 | val acc: 44.31%\n",
      "epoch 18/20 | loss: 1.2911 | val acc: 47.18%\n",
      "epoch 19/20 | loss: 1.1542 | val acc: 51.78%\n",
      "epoch 20/20 | loss: 0.9995 | val acc: 55.12%\n",
      "testing learning rate: 0.0001\n",
      "Using device: cuda\n",
      "\n",
      "training LSTM (output dim: 7) for 10 epochs\n",
      "epoch 1/10 | loss: 1.9301 | val acc: 17.92%\n",
      "epoch 2/10 | loss: 1.9214 | val acc: 18.08%\n",
      "epoch 3/10 | loss: 1.8106 | val acc: 25.44%\n",
      "epoch 4/10 | loss: 1.6685 | val acc: 28.42%\n",
      "epoch 5/10 | loss: 1.6578 | val acc: 31.92%\n",
      "epoch 6/10 | loss: 1.5634 | val acc: 29.99%\n",
      "epoch 7/10 | loss: 1.6917 | val acc: 35.48%\n",
      "epoch 8/10 | loss: 1.4877 | val acc: 36.73%\n",
      "epoch 9/10 | loss: 1.5019 | val acc: 40.80%\n",
      "epoch 10/10 | loss: 1.3873 | val acc: 42.74%\n",
      "Using device: cuda\n",
      "\n",
      "training LSTM (output dim: 33) for 20 epochs\n",
      "epoch 1/20 | loss: 3.4916 | val acc: 3.40%\n",
      "epoch 2/20 | loss: 3.4795 | val acc: 4.55%\n",
      "epoch 3/20 | loss: 3.4601 | val acc: 5.90%\n",
      "epoch 4/20 | loss: 3.3205 | val acc: 5.49%\n",
      "epoch 5/20 | loss: 3.2147 | val acc: 6.43%\n",
      "epoch 6/20 | loss: 3.1928 | val acc: 7.89%\n",
      "epoch 7/20 | loss: 3.1861 | val acc: 7.68%\n",
      "epoch 8/20 | loss: 3.2016 | val acc: 8.15%\n",
      "epoch 9/20 | loss: 3.0570 | val acc: 7.84%\n",
      "epoch 10/20 | loss: 2.9667 | val acc: 8.99%\n",
      "epoch 11/20 | loss: 2.9707 | val acc: 8.10%\n",
      "epoch 12/20 | loss: 2.9276 | val acc: 9.35%\n",
      "epoch 13/20 | loss: 2.9481 | val acc: 9.04%\n",
      "epoch 14/20 | loss: 2.9315 | val acc: 8.46%\n",
      "epoch 15/20 | loss: 2.9507 | val acc: 9.04%\n",
      "epoch 16/20 | loss: 2.9480 | val acc: 9.25%\n",
      "epoch 17/20 | loss: 2.9320 | val acc: 10.40%\n",
      "epoch 18/20 | loss: 2.9379 | val acc: 8.46%\n",
      "epoch 19/20 | loss: 2.9591 | val acc: 11.02%\n",
      "epoch 20/20 | loss: 2.9347 | val acc: 9.51%\n",
      "saved plot to: plots/Effect_of_Learning_Rate.png\n"
     ]
    }
   ],
   "source": [
    "# 2) test learning rate\n",
    "lr_list = [1e-3, 1e-4]\n",
    "lstm_res_domain_lr = []\n",
    "lstm_res_sub_lr = []\n",
    "\n",
    "for lr in lr_list:\n",
    "    print(f\"testing learning rate: {lr}\")\n",
    "    lstm_res_domain_lr.append(\n",
    "        evaluate_lstm(train_ds, val_ds, vocab_size, output_dim_domain, embedding_matrix=embedding_matrix,\n",
    "                      dropout=BEST_DROPOUT_LSTM_DOMAIN, lr=lr))\n",
    "    lstm_res_sub_lr.append(\n",
    "        evaluate_lstm(train_ds, val_ds, vocab_size, output_dim_sub, embedding_matrix=embedding_matrix,\n",
    "                      dropout=BEST_DROPOUT_LSTM_SUB, lr=lr, epochs=20))\n",
    "\n",
    "plot_combined_results(lr_list, lstm_res_domain_lr, lstm_res_sub_lr, \"Effect of Learning Rate\", \"Learning Rate\")\n",
    "\n",
    "BEST_LR_LSTM_DOMAIN = lr_list[np.argmax(lstm_res_domain_lr)]\n",
    "BEST_LR_LSTM_SUB = lr_list[np.argmax(lstm_res_sub_lr)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "00a38fbc-561e-4ad4-b742-ad006bd4debe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing hidden size: 256\n",
      "Using device: cuda\n",
      "\n",
      "training LSTM (output dim: 7) for 10 epochs\n",
      "epoch 1/10 | loss: 1.9142 | val acc: 27.22%\n",
      "epoch 2/10 | loss: 1.8457 | val acc: 28.11%\n",
      "epoch 3/10 | loss: 1.6159 | val acc: 23.41%\n",
      "epoch 4/10 | loss: 1.6962 | val acc: 30.72%\n",
      "epoch 5/10 | loss: 1.3851 | val acc: 54.02%\n",
      "epoch 6/10 | loss: 0.9582 | val acc: 66.67%\n",
      "epoch 7/10 | loss: 0.7153 | val acc: 68.91%\n",
      "epoch 8/10 | loss: 0.5049 | val acc: 77.64%\n",
      "epoch 9/10 | loss: 0.3702 | val acc: 79.36%\n",
      "epoch 10/10 | loss: 0.2644 | val acc: 85.95%\n",
      "Using device: cuda\n",
      "\n",
      "training LSTM (output dim: 33) for 20 epochs\n",
      "epoch 1/20 | loss: 3.4889 | val acc: 3.61%\n",
      "epoch 2/20 | loss: 3.4601 | val acc: 5.64%\n",
      "epoch 3/20 | loss: 3.3935 | val acc: 3.87%\n",
      "epoch 4/20 | loss: 3.2428 | val acc: 7.26%\n",
      "epoch 5/20 | loss: 3.1559 | val acc: 7.42%\n",
      "epoch 6/20 | loss: 3.0550 | val acc: 8.46%\n",
      "epoch 7/20 | loss: 2.9720 | val acc: 11.86%\n",
      "epoch 8/20 | loss: 2.7380 | val acc: 13.74%\n",
      "epoch 9/20 | loss: 2.6605 | val acc: 15.52%\n",
      "epoch 10/20 | loss: 2.5564 | val acc: 14.05%\n",
      "epoch 11/20 | loss: 2.4841 | val acc: 19.80%\n",
      "epoch 12/20 | loss: 2.1602 | val acc: 25.86%\n",
      "epoch 13/20 | loss: 2.0081 | val acc: 31.97%\n",
      "epoch 14/20 | loss: 1.8558 | val acc: 34.12%\n",
      "epoch 15/20 | loss: 1.6808 | val acc: 35.84%\n",
      "epoch 16/20 | loss: 1.5436 | val acc: 39.86%\n",
      "epoch 17/20 | loss: 1.4533 | val acc: 40.70%\n",
      "epoch 18/20 | loss: 1.3449 | val acc: 46.66%\n",
      "epoch 19/20 | loss: 1.1873 | val acc: 51.46%\n",
      "epoch 20/20 | loss: 1.0253 | val acc: 52.72%\n",
      "testing hidden size: 512\n",
      "Using device: cuda\n",
      "\n",
      "training LSTM (output dim: 7) for 10 epochs\n",
      "epoch 1/10 | loss: 1.9468 | val acc: 17.61%\n",
      "epoch 2/10 | loss: 1.6949 | val acc: 29.15%\n",
      "epoch 3/10 | loss: 1.5326 | val acc: 39.66%\n",
      "epoch 4/10 | loss: 1.5994 | val acc: 32.92%\n",
      "epoch 5/10 | loss: 1.3144 | val acc: 45.61%\n",
      "epoch 6/10 | loss: 1.0448 | val acc: 63.48%\n",
      "epoch 7/10 | loss: 0.4999 | val acc: 88.56%\n",
      "epoch 8/10 | loss: 0.2174 | val acc: 91.01%\n",
      "epoch 9/10 | loss: 0.1328 | val acc: 91.07%\n",
      "epoch 10/10 | loss: 0.0849 | val acc: 90.23%\n",
      "Using device: cuda\n",
      "\n",
      "training LSTM (output dim: 33) for 20 epochs\n",
      "epoch 1/20 | loss: 3.4916 | val acc: 2.87%\n",
      "epoch 2/20 | loss: 3.4591 | val acc: 5.54%\n",
      "epoch 3/20 | loss: 3.2755 | val acc: 6.58%\n",
      "epoch 4/20 | loss: 3.0980 | val acc: 9.09%\n",
      "epoch 5/20 | loss: 3.1231 | val acc: 3.97%\n",
      "epoch 6/20 | loss: 3.1283 | val acc: 10.82%\n",
      "epoch 7/20 | loss: 2.8403 | val acc: 10.14%\n",
      "epoch 8/20 | loss: 2.4826 | val acc: 15.88%\n",
      "epoch 9/20 | loss: 2.1215 | val acc: 23.35%\n",
      "epoch 10/20 | loss: 1.7446 | val acc: 36.68%\n",
      "epoch 11/20 | loss: 1.3077 | val acc: 54.49%\n",
      "epoch 12/20 | loss: 0.9000 | val acc: 66.46%\n",
      "epoch 13/20 | loss: 0.6197 | val acc: 70.74%\n",
      "epoch 14/20 | loss: 0.4617 | val acc: 72.73%\n",
      "epoch 15/20 | loss: 0.3080 | val acc: 75.55%\n",
      "epoch 16/20 | loss: 0.2351 | val acc: 75.44%\n",
      "epoch 17/20 | loss: 0.1727 | val acc: 75.97%\n",
      "epoch 18/20 | loss: 0.1294 | val acc: 75.44%\n",
      "epoch 19/20 | loss: 0.0970 | val acc: 76.85%\n",
      "epoch 20/20 | loss: 0.0857 | val acc: 76.80%\n",
      "saved plot to: plots/Effect_of_Hidden_Size.png\n"
     ]
    }
   ],
   "source": [
    "# 3) test hidden size\n",
    "hidden_size_list = [256, 512]\n",
    "lstm_res_domain_hidden = []\n",
    "lstm_res_sub_hidden = []\n",
    "\n",
    "for hs in hidden_size_list:\n",
    "    print(f\"testing hidden size: {hs}\")\n",
    "    lstm_res_domain_hidden.append(\n",
    "        evaluate_lstm(train_ds, val_ds, vocab_size, output_dim_domain, embedding_matrix=embedding_matrix,\n",
    "                      dropout=BEST_DROPOUT_LSTM_DOMAIN, lr=BEST_LR_LSTM_DOMAIN, hidden_size=hs))\n",
    "    lstm_res_sub_hidden.append(\n",
    "        evaluate_lstm(train_ds, val_ds, vocab_size, output_dim_sub, embedding_matrix=embedding_matrix,\n",
    "                      dropout=BEST_DROPOUT_LSTM_SUB, lr=BEST_LR_LSTM_SUB, hidden_size=hs, epochs=20))\n",
    "\n",
    "plot_combined_results(hidden_size_list, lstm_res_domain_hidden, lstm_res_sub_hidden, \"Effect of Hidden Size\",\n",
    "                      \"Hidden Size\")\n",
    "\n",
    "BEST_HS_LSTM_DOMAIN = hidden_size_list[np.argmax(lstm_res_domain_hidden)]\n",
    "BEST_HS_LSTM_SUB = hidden_size_list[np.argmax(lstm_res_sub_hidden)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4ed0783c-85ed-4599-85ed-441b7627b3aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing initialization type: xavier\n",
      "Using device: cuda\n",
      "\n",
      "training LSTM (output dim: 7) for 10 epochs\n",
      "epoch 1/10 | loss: 1.9276 | val acc: 19.54%\n",
      "epoch 2/10 | loss: 1.7110 | val acc: 29.41%\n",
      "epoch 3/10 | loss: 1.7796 | val acc: 18.91%\n",
      "epoch 4/10 | loss: 1.5704 | val acc: 32.92%\n",
      "epoch 5/10 | loss: 1.1343 | val acc: 45.82%\n",
      "epoch 6/10 | loss: 0.7884 | val acc: 74.19%\n",
      "epoch 7/10 | loss: 0.4282 | val acc: 84.54%\n",
      "epoch 8/10 | loss: 0.2420 | val acc: 88.14%\n",
      "epoch 9/10 | loss: 0.1471 | val acc: 88.14%\n",
      "epoch 10/10 | loss: 0.0986 | val acc: 89.24%\n",
      "testing initialization type: random\n",
      "Using device: cuda\n",
      "\n",
      "training LSTM (output dim: 7) for 10 epochs\n",
      "epoch 1/10 | loss: 1.9405 | val acc: 16.88%\n",
      "epoch 2/10 | loss: 1.8959 | val acc: 27.38%\n",
      "epoch 3/10 | loss: 1.6271 | val acc: 28.63%\n",
      "epoch 4/10 | loss: 1.6080 | val acc: 28.16%\n",
      "epoch 5/10 | loss: 1.5728 | val acc: 25.97%\n",
      "epoch 6/10 | loss: 1.4489 | val acc: 30.77%\n",
      "epoch 7/10 | loss: 1.4709 | val acc: 30.77%\n",
      "epoch 8/10 | loss: 1.4904 | val acc: 42.58%\n",
      "epoch 9/10 | loss: 1.2799 | val acc: 60.19%\n",
      "epoch 10/10 | loss: 0.9047 | val acc: 71.32%\n",
      "testing initialization type: zero\n",
      "Using device: cuda\n",
      "\n",
      "training LSTM (output dim: 7) for 10 epochs\n",
      "epoch 1/10 | loss: 1.9274 | val acc: 19.07%\n",
      "epoch 2/10 | loss: 1.7013 | val acc: 26.49%\n",
      "epoch 3/10 | loss: 1.6546 | val acc: 24.19%\n",
      "epoch 4/10 | loss: 1.5125 | val acc: 42.95%\n",
      "epoch 5/10 | loss: 1.2719 | val acc: 49.16%\n",
      "epoch 6/10 | loss: 0.9288 | val acc: 72.78%\n",
      "epoch 7/10 | loss: 0.4406 | val acc: 86.83%\n",
      "epoch 8/10 | loss: 0.2277 | val acc: 87.98%\n",
      "epoch 9/10 | loss: 0.1323 | val acc: 89.18%\n",
      "epoch 10/10 | loss: 0.0851 | val acc: 89.66%\n",
      "saved plot to: plots/Effect_of_Initialization.png\n"
     ]
    }
   ],
   "source": [
    "# 4) test init type for LSTM\n",
    "init_types = ['xavier', 'random', 'zero']\n",
    "init_results = []\n",
    "\n",
    "for hs in init_types:\n",
    "    print(f\"testing initialization type: {hs}\")\n",
    "\n",
    "    l_acc_domain = evaluate_lstm(\n",
    "        train_ds, val_ds, vocab_size, output_dim_domain,\n",
    "        embedding_matrix=embedding_matrix,\n",
    "        dropout=BEST_DROPOUT_LSTM_DOMAIN,\n",
    "        lr=BEST_LR_LSTM_DOMAIN,\n",
    "        hidden_size=BEST_HS_LSTM_DOMAIN,\n",
    "    )\n",
    "    init_results.append(l_acc_domain)\n",
    "\n",
    "plot_single_result(init_types, init_results, \"Effect of Initialization\", \"Init Type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5d1fb588-381c-4e06-9798-6a61051741e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GloVe dimension comparison\n",
      "\n",
      "testing GloVe dimension: 50d\n",
      "GloVe loaded. Found 9853 / 10000 words.\n",
      "Using device: cuda\n",
      "\n",
      "training LSTM (output dim: 7) for 10 epochs\n",
      "epoch 1/10 | loss: 1.9299 | val acc: 16.61%\n",
      "epoch 2/10 | loss: 1.9168 | val acc: 27.38%\n",
      "epoch 3/10 | loss: 1.6502 | val acc: 30.25%\n",
      "epoch 4/10 | loss: 1.8772 | val acc: 13.58%\n",
      "epoch 5/10 | loss: 1.8021 | val acc: 23.09%\n",
      "epoch 6/10 | loss: 1.5975 | val acc: 35.84%\n",
      "epoch 7/10 | loss: 1.3907 | val acc: 46.39%\n",
      "epoch 8/10 | loss: 1.1344 | val acc: 53.92%\n",
      "epoch 9/10 | loss: 0.9322 | val acc: 64.79%\n",
      "epoch 10/10 | loss: 0.7123 | val acc: 72.05%\n",
      "\n",
      "testing GloVe dimension: 100d\n",
      "GloVe loaded. Found 9853 / 10000 words.\n",
      "Using device: cuda\n",
      "\n",
      "training LSTM (output dim: 7) for 10 epochs\n",
      "epoch 1/10 | loss: 1.9281 | val acc: 17.92%\n",
      "epoch 2/10 | loss: 1.8269 | val acc: 29.05%\n",
      "epoch 3/10 | loss: 1.7592 | val acc: 18.08%\n",
      "epoch 4/10 | loss: 1.9046 | val acc: 16.98%\n",
      "epoch 5/10 | loss: 1.8366 | val acc: 14.99%\n",
      "epoch 6/10 | loss: 1.3199 | val acc: 56.17%\n",
      "epoch 7/10 | loss: 0.7684 | val acc: 76.18%\n",
      "epoch 8/10 | loss: 0.4185 | val acc: 87.04%\n",
      "epoch 9/10 | loss: 0.2493 | val acc: 88.04%\n",
      "epoch 10/10 | loss: 0.1634 | val acc: 88.40%\n",
      "\n",
      "testing GloVe dimension: 200d\n",
      "GloVe loaded. Found 9853 / 10000 words.\n",
      "Using device: cuda\n",
      "\n",
      "training LSTM (output dim: 7) for 10 epochs\n",
      "epoch 1/10 | loss: 1.9281 | val acc: 18.03%\n",
      "epoch 2/10 | loss: 1.8740 | val acc: 28.79%\n",
      "epoch 3/10 | loss: 1.7079 | val acc: 27.80%\n",
      "epoch 4/10 | loss: 1.5302 | val acc: 40.28%\n",
      "epoch 5/10 | loss: 1.2829 | val acc: 52.09%\n",
      "epoch 6/10 | loss: 0.9620 | val acc: 62.02%\n",
      "epoch 7/10 | loss: 0.7732 | val acc: 65.94%\n",
      "epoch 8/10 | loss: 0.5883 | val acc: 78.47%\n",
      "epoch 9/10 | loss: 0.3673 | val acc: 86.15%\n",
      "epoch 10/10 | loss: 0.2127 | val acc: 86.78%\n",
      "\n",
      "testing GloVe dimension: 300d\n",
      "GloVe loaded. Found 9853 / 10000 words.\n",
      "Using device: cuda\n",
      "\n",
      "training LSTM (output dim: 7) for 10 epochs\n",
      "epoch 1/10 | loss: 1.9034 | val acc: 16.51%\n",
      "epoch 2/10 | loss: 1.9344 | val acc: 18.13%\n",
      "epoch 3/10 | loss: 1.6436 | val acc: 29.00%\n",
      "epoch 4/10 | loss: 1.4367 | val acc: 37.46%\n",
      "epoch 5/10 | loss: 1.3180 | val acc: 45.14%\n",
      "epoch 6/10 | loss: 1.1354 | val acc: 48.90%\n",
      "epoch 7/10 | loss: 0.7939 | val acc: 64.16%\n",
      "epoch 8/10 | loss: 0.5838 | val acc: 73.56%\n",
      "epoch 9/10 | loss: 0.4206 | val acc: 81.50%\n",
      "epoch 10/10 | loss: 0.2797 | val acc: 84.54%\n"
     ]
    }
   ],
   "source": [
    "# 6) Embedding Dimension Comparison (50d vs 100d vs 200d vs 300d)\n",
    "print(\"GloVe dimension comparison\")\n",
    "GLOVE_DIR = \"glove.6B\"\n",
    "glove_dims = [50, 100, 200, 300]\n",
    "dim_results = []\n",
    "\n",
    "for dim in glove_dims:\n",
    "    filename = f\"glove.6B.{dim}d.txt\"\n",
    "    path = os.path.join(GLOVE_DIR, filename)\n",
    "\n",
    "    print(f\"\\ntesting GloVe dimension: {dim}d\")\n",
    "\n",
    "    # load specific matrix for this dimension\n",
    "    # pass 'dim' so the parser knows the vector size\n",
    "    current_matrix = load_glove_matrix(path, vocab, embed_dim=dim)\n",
    "\n",
    "    acc = evaluate_lstm(\n",
    "        train_ds, val_ds, vocab_size, output_dim_domain,\n",
    "        embedding_matrix=current_matrix,\n",
    "        dropout=BEST_DROPOUT_LSTM_DOMAIN,\n",
    "        lr=BEST_LR_LSTM_DOMAIN,\n",
    "        hidden_size=BEST_HS_LSTM_DOMAIN,\n",
    "        epochs=10\n",
    "    )\n",
    "    dim_results.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "da534c7e-6a52-4898-8851-b8454ea2662e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved plot to: plots/Effect_of_Embedding_Dimension.png\n"
     ]
    }
   ],
   "source": [
    "dim_labels = [str(d) for d in glove_dims]\n",
    "plot_single_result(dim_labels, dim_results, \"Effect of Embedding Dimension\", \"GloVe Dimension\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "62186fb8-34a2-4a78-90e5-eccbdbe96684",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear VRAM before heavy lifting\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3ecfc814-d9f4-4869-af87-695578771729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- EXP 1/4: Custom LSTM (Domain) ---\n",
      "Using device: cuda\n",
      "\n",
      "training LSTM (output dim: 7) for 10 epochs\n",
      "epoch 1/10 | loss: 1.8983 | val acc: 23.56%\n",
      "epoch 2/10 | loss: 1.8022 | val acc: 16.35%\n",
      "epoch 3/10 | loss: 1.9315 | val acc: 24.92%\n",
      "epoch 4/10 | loss: 1.6113 | val acc: 46.19%\n",
      "epoch 5/10 | loss: 1.0921 | val acc: 56.74%\n",
      "epoch 6/10 | loss: 0.8923 | val acc: 72.05%\n",
      "epoch 7/10 | loss: 0.6221 | val acc: 80.41%\n",
      "epoch 8/10 | loss: 0.4084 | val acc: 84.27%\n",
      "epoch 9/10 | loss: 0.2715 | val acc: 82.03%\n",
      "epoch 10/10 | loss: 0.2941 | val acc: 86.99%\n",
      "Final LSTM Domain Test Acc: 86.46%\n"
     ]
    }
   ],
   "source": [
    "# 1) LSTM Domain\n",
    "print(\"\\n--- EXP 1/4: Custom LSTM (Domain) ---\")\n",
    "lstm_domain = CustomLSTMModel(vocab_size, EMBED_DIM, output_dim_domain, hidden_size=BEST_HS_LSTM_DOMAIN,\n",
    "                              embedding_matrix=embedding_matrix, dropout=BEST_DROPOUT_LSTM_DOMAIN)\n",
    "lstm_domain.fit(train_loader, val_loader, epochs=10)\n",
    "test_acc_domain_lstm = lstm_domain.evaluate_acc(test_loader)\n",
    "print(f\"Final LSTM Domain Test Acc: {test_acc_domain_lstm:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "89da7391-704e-43af-8d18-a71ffe179fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- EXP 2/4: BERT (Domain) ---\n",
      "Using device: cuda\n",
      "starting BERT fine-tuning\n",
      "epoch 1/3 [81.3s] | train loss: 0.7663 acc: 0.7649 | val loss: 0.2998 acc: 0.9175\n",
      "epoch 2/3 [81.2s] | train loss: 0.2372 acc: 0.9333 | val loss: 0.2645 acc: 0.9211\n",
      "epoch 3/3 [81.2s] | train loss: 0.1472 acc: 0.9617 | val loss: 0.2560 acc: 0.9248\n",
      "Final BERT Domain Test Acc: 92.77%\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- EXP 2/4: BERT (Domain) ---\")\n",
    "bert_domain_model = BERTClassifier(output_dim=output_dim_domain)\n",
    "bert_domain_train_ldr = DataLoader(\n",
    "    TensorDataset(bert_train_enc['input_ids'], bert_train_enc['attention_mask'], bert_domain_train_labels),\n",
    "    batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY)\n",
    "bert_domain_val_ldr = DataLoader(\n",
    "    TensorDataset(bert_val_enc['input_ids'], bert_val_enc['attention_mask'], bert_domain_val_labels),\n",
    "    batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY)\n",
    "\n",
    "bert_domain_model.fit(bert_domain_train_ldr, bert_domain_val_ldr, epochs=3)\n",
    "bert_test_loader, _, _, _ = get_bert_test_data(all_texts, y_domain_raw, test_indices)\n",
    "_, bert_test_acc = bert_domain_model.evaluate(bert_test_loader, nn.CrossEntropyLoss())\n",
    "test_acc_domain_bert = bert_test_acc * 100\n",
    "print(f\"Final BERT Domain Test Acc: {test_acc_domain_bert:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "65f88319-871d-4904-9c81-3d1b509660ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2886e299-4745-48ac-8710-7f8ae74f49fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- EXP 3/4: Custom LSTM (Sub-field) ---\n",
      "Using device: cuda\n",
      "\n",
      "training LSTM (output dim: 33) for 25 epochs\n",
      "epoch 1/25 | loss: 3.4881 | val acc: 3.50%\n",
      "epoch 2/25 | loss: 3.4661 | val acc: 3.29%\n",
      "epoch 3/25 | loss: 3.4476 | val acc: 4.55%\n",
      "epoch 4/25 | loss: 3.3263 | val acc: 6.17%\n",
      "epoch 5/25 | loss: 3.3416 | val acc: 3.61%\n",
      "epoch 6/25 | loss: 3.2445 | val acc: 6.48%\n",
      "epoch 7/25 | loss: 3.1756 | val acc: 4.34%\n",
      "epoch 8/25 | loss: 3.2061 | val acc: 6.27%\n",
      "epoch 9/25 | loss: 2.9977 | val acc: 7.31%\n",
      "epoch 10/25 | loss: 2.9820 | val acc: 5.12%\n",
      "epoch 11/25 | loss: 3.1118 | val acc: 11.44%\n",
      "epoch 12/25 | loss: 2.6768 | val acc: 16.35%\n",
      "epoch 13/25 | loss: 2.4092 | val acc: 21.79%\n",
      "epoch 14/25 | loss: 2.1525 | val acc: 25.55%\n",
      "epoch 15/25 | loss: 1.9664 | val acc: 31.09%\n",
      "epoch 16/25 | loss: 1.7298 | val acc: 38.45%\n",
      "epoch 17/25 | loss: 1.4613 | val acc: 43.83%\n",
      "epoch 18/25 | loss: 1.2064 | val acc: 54.70%\n",
      "epoch 19/25 | loss: 0.8828 | val acc: 63.90%\n",
      "epoch 20/25 | loss: 0.6495 | val acc: 69.96%\n",
      "epoch 21/25 | loss: 0.5200 | val acc: 71.26%\n",
      "epoch 22/25 | loss: 0.4129 | val acc: 74.50%\n",
      "epoch 23/25 | loss: 0.2941 | val acc: 76.12%\n",
      "epoch 24/25 | loss: 0.2295 | val acc: 74.97%\n",
      "epoch 25/25 | loss: 0.1846 | val acc: 77.12%\n",
      "Final LSTM Sub-field Test Acc: 75.14%\n"
     ]
    }
   ],
   "source": [
    "# 3) LSTM Sub-field\n",
    "print(\"\\n--- EXP 3/4: Custom LSTM (Sub-field) ---\")\n",
    "lstm_sub = CustomLSTMModel(vocab_size, EMBED_DIM, output_dim_sub, hidden_size=BEST_HS_LSTM_SUB,\n",
    "                           embedding_matrix=embedding_matrix, dropout=BEST_DROPOUT_LSTM_SUB)\n",
    "lstm_sub.fit(train_loader, val_loader, epochs=25)\n",
    "test_acc_sub_lstm = lstm_sub.evaluate_acc(test_loader)\n",
    "print(f\"Final LSTM Sub-field Test Acc: {test_acc_sub_lstm:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "00fb336d-ef09-41a1-b096-aa6373d9244f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- EXP 4/4: BERT (Sub-field) ---\n",
      "Using device: cuda\n",
      "starting BERT fine-tuning\n",
      "epoch 1/3 [81.3s] | train loss: 2.5182 acc: 0.4018 | val loss: 1.4264 acc: 0.7759\n",
      "epoch 2/3 [81.3s] | train loss: 1.1118 acc: 0.8292 | val loss: 0.8206 acc: 0.8459\n",
      "epoch 3/3 [81.3s] | train loss: 0.7386 acc: 0.8843 | val loss: 0.7160 acc: 0.8558\n",
      "Final BERT Sub-field Test Acc: 85.96%\n"
     ]
    }
   ],
   "source": [
    "# 4) BERT Sub-field\n",
    "print(\"\\n--- EXP 4/4: BERT (Sub-field) ---\")\n",
    "bert_sub_model = BERTClassifier(output_dim=output_dim_sub)\n",
    "bert_sub_train_ldr = DataLoader(\n",
    "    TensorDataset(bert_train_enc['input_ids'], bert_train_enc['attention_mask'], bert_sub_train_labels),\n",
    "    batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY)\n",
    "bert_sub_val_ldr = DataLoader(\n",
    "    TensorDataset(bert_val_enc['input_ids'], bert_val_enc['attention_mask'], bert_sub_val_labels),\n",
    "    batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY)\n",
    "\n",
    "bert_sub_model.fit(bert_sub_train_ldr, bert_sub_val_ldr, epochs=3)\n",
    "bert_sub_test_loader, _, _, _ = get_bert_test_data(all_texts, y_sub_raw, test_indices)\n",
    "_, bert_sub_test_acc = bert_sub_model.evaluate(bert_sub_test_loader, nn.CrossEntropyLoss())\n",
    "test_acc_sub_bert = bert_sub_test_acc * 100\n",
    "print(f\"Final BERT Sub-field Test Acc: {test_acc_sub_bert:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6d3ea05d-38a0-41e5-8715-b11738042da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample_data(model, data_loader):\n",
    "    model.eval()\n",
    "    correct_data = None\n",
    "    incorrect_data = None\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "    # Iterate through batch to find specific cases\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            b_input_ids, b_input_mask, b_labels = [b.to(model.device) for b in batch]\n",
    "            logits = model(b_input_ids, b_input_mask)\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "\n",
    "            correct_mask = preds == b_labels\n",
    "            incorrect_mask = preds != b_labels\n",
    "\n",
    "            if correct_data is None and correct_mask.any():\n",
    "                idx = torch.where(correct_mask)[0][0]\n",
    "                correct_data = (b_input_ids[idx].unsqueeze(0), b_input_mask[idx].unsqueeze(0))\n",
    "\n",
    "            if incorrect_data is None and incorrect_mask.any():\n",
    "                idx = torch.where(incorrect_mask)[0][0]\n",
    "                incorrect_data = (b_input_ids[idx].unsqueeze(0), b_input_mask[idx].unsqueeze(0))\n",
    "\n",
    "            if correct_data is not None and incorrect_data is not None:\n",
    "                break\n",
    "\n",
    "    # Fallback to avoid NoneType crash if model is 100% correct or 0% correct\n",
    "    if correct_data is None:\n",
    "        # Just grab the first available batch\n",
    "        for batch in data_loader:\n",
    "            b_input_ids, b_input_mask, _ = [b.to(model.device) for b in batch]\n",
    "            correct_data = (b_input_ids[0].unsqueeze(0), b_input_mask[0].unsqueeze(0))\n",
    "            break\n",
    "\n",
    "    if incorrect_data is None:\n",
    "        # Just grab the first available batch\n",
    "        for batch in data_loader:\n",
    "            b_input_ids, b_input_mask, _ = [b.to(model.device) for b in batch]\n",
    "            incorrect_data = (b_input_ids[0].unsqueeze(0), b_input_mask[0].unsqueeze(0))\n",
    "            break\n",
    "\n",
    "    return correct_data, incorrect_data, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b69c2bbc-7ae0-4729-a0ee-3c6643f109e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_attention(model, tokenizer, input_ids, attention_mask, title_prefix, device, layer_idx=11, head_idx=0,\n",
    "                        save_dir=\"plots\"):\n",
    "    model.eval()\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    attentions = model.get_attention_maps(input_ids, attention_mask)\n",
    "    attention_matrix = attentions[layer_idx][0, head_idx, :, :].cpu().detach().numpy()\n",
    "    tokens = tokenizer.convert_ids_to_tokens(input_ids[0])\n",
    "\n",
    "    seq_len = attention_mask.sum().item()\n",
    "    attention_matrix = attention_matrix[:seq_len, :seq_len]\n",
    "    tokens = tokens[:seq_len]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    sns.heatmap(attention_matrix, xticklabels=tokens, yticklabels=tokens, cmap='viridis', ax=ax)\n",
    "    title = f\"{title_prefix} - Layer {layer_idx + 1}, Head {head_idx + 1}\"\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(\"Key\")\n",
    "    ax.set_ylabel(\"Query\")\n",
    "    plt.xticks(rotation=90)\n",
    "\n",
    "    clean_title = title.replace(\" \", \"_\").replace(\":\", \"\").replace(\",\", \"\")\n",
    "    fig.savefig(os.path.join(save_dir, f\"{clean_title}.png\"), bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "    print(f\"saved attention map: {clean_title}.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5251603e-6398-4015-ad82-259d6832deaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_token_importance(model, tokenizer, input_ids, attention_mask, title_prefix, device, layer_idx=11,\n",
    "                               head_idx=0, save_dir=\"plots\"):\n",
    "    model.eval()\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    attentions = model.get_attention_maps(input_ids, attention_mask)\n",
    "    cls_attention = attentions[layer_idx][0, head_idx, 0, :].cpu().detach().numpy()\n",
    "    tokens = tokenizer.convert_ids_to_tokens(input_ids[0])\n",
    "\n",
    "    valid_tokens = []\n",
    "    valid_scores = []\n",
    "    for token, score in zip(tokens, cls_attention):\n",
    "        if token not in ['[CLS]', '[SEP]', '[PAD]']:\n",
    "            valid_tokens.append(token)\n",
    "            valid_scores.append(score)\n",
    "\n",
    "    sorted_indices = np.argsort(valid_scores)[::-1]\n",
    "    top_n = 15\n",
    "    top_tokens = [valid_tokens[i] for i in sorted_indices[:top_n]]\n",
    "    top_scores = [valid_scores[i] for i in sorted_indices[:top_n]]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    y_pos = np.arange(len(top_tokens))\n",
    "    ax.barh(y_pos, top_scores, align='center', color='skyblue')\n",
    "    ax.set_yticks(y_pos)\n",
    "    ax.set_yticklabels(top_tokens)\n",
    "    ax.invert_yaxis()\n",
    "    title = f\"{title_prefix} Top Tokens\"\n",
    "    ax.set_title(title)\n",
    "\n",
    "    clean_title = title.replace(\" \", \"_\")\n",
    "    fig.savefig(os.path.join(save_dir, f\"{clean_title}.png\"), bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "    print(f\"Saved importance plot: {clean_title}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d5d87999-4249-4924-a2ce-c7ff71a2d2db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved attention map: Correct_-_Layer_12_Head_1.png\n",
      "saved attention map: Incorrect_-_Layer_12_Head_1.png\n",
      "Saved importance plot: Correct_Top_Tokens.png\n",
      "Saved importance plot: Incorrect_Top_Tokens.png\n"
     ]
    }
   ],
   "source": [
    "# Run Analysis\n",
    "bert_test_loader_domain, _, _, _ = get_bert_test_data(all_texts, y_domain_raw, test_indices)\n",
    "correct_data, incorrect_data, tokenizer = get_sample_data(bert_domain_model, bert_test_loader_domain)\n",
    "\n",
    "visualize_attention(bert_domain_model, tokenizer, correct_data[0], correct_data[1], \"Correct\", DEVICE)\n",
    "visualize_attention(bert_domain_model, tokenizer, incorrect_data[0], incorrect_data[1], \"Incorrect\", DEVICE)\n",
    "\n",
    "visualize_token_importance(bert_domain_model, tokenizer, correct_data[0], correct_data[1], \"Correct\", DEVICE)\n",
    "visualize_token_importance(bert_domain_model, tokenizer, incorrect_data[0], incorrect_data[1], \"Incorrect\", DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "593f8007-910f-443f-b0b9-3031569e31f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- RESULTS SUMMARY TABLE ---\n",
      "| Model | Task | Test Accuracy | Winner? |\n",
      "|---|---|---|---|\n",
      "| Custom LSTM (GloVe) | Domain (7 Classes) | 86.46% |  |\n",
      "| BERT Classifier | Domain (7 Classes) | 92.77% | <-- |\n",
      "| Custom LSTM (GloVe) | Sub-field (33 Classes) | 75.14% |  |\n",
      "| BERT Classifier | Sub-field (33 Classes) | 85.96% | <-- |\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- RESULTS SUMMARY TABLE ---\")\n",
    "print(\"| Model | Task | Test Accuracy | Winner? |\")\n",
    "print(\"|---|---|---|---|\")\n",
    "print(\n",
    "    f\"| Custom LSTM (GloVe) | Domain (7 Classes) | {test_acc_domain_lstm:.2f}% | {'<--' if test_acc_domain_lstm > test_acc_domain_bert else ''} |\")\n",
    "print(\n",
    "    f\"| BERT Classifier | Domain (7 Classes) | {test_acc_domain_bert:.2f}% | {'<--' if test_acc_domain_bert > test_acc_domain_lstm else ''} |\")\n",
    "print(\n",
    "    f\"| Custom LSTM (GloVe) | Sub-field (33 Classes) | {test_acc_sub_lstm:.2f}% | {'<--' if test_acc_sub_lstm > test_acc_sub_bert else ''} |\")\n",
    "print(\n",
    "    f\"| BERT Classifier | Sub-field (33 Classes) | {test_acc_sub_bert:.2f}% | {'<--' if test_acc_sub_bert > test_acc_sub_lstm else ''} |\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "43a80bda-8f95-4c7a-ab7f-7b4a3ec151ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_comparison(test_acc_domain_lstm, test_acc_domain_bert,\n",
    "                          test_acc_sub_lstm, test_acc_sub_bert,\n",
    "                          save_path=\"plots/model_comparison.png\"):\n",
    "\n",
    "    # Data preparation\n",
    "    tasks = ['Domain (7 Classes)', 'Sub-field (33 Classes)']\n",
    "    lstm_scores = [test_acc_domain_lstm, test_acc_sub_lstm]\n",
    "    bert_scores = [test_acc_domain_bert, test_acc_sub_bert]\n",
    "\n",
    "    x = np.arange(len(tasks))  # label locations\n",
    "    width = 0.35  # width of the bars\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "    # Plotting the bars\n",
    "    rects1 = ax.bar(x - width/2, lstm_scores, width, label='Custom LSTM (GloVe)', color='skyblue')\n",
    "    rects2 = ax.bar(x + width/2, bert_scores, width, label='BERT Classifier', color='salmon')\n",
    "\n",
    "    # Formatting\n",
    "    ax.set_ylabel('Test Accuracy (%)')\n",
    "    ax.set_title('Model Performance Comparison')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(tasks)\n",
    "    ax.set_ylim(0, 100)  # Set y-axis to 0-100% for context\n",
    "    ax.legend()\n",
    "    ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "    # Helper function to put text labels on top of bars\n",
    "    def autolabel(rects):\n",
    "        for rect in rects:\n",
    "            height = rect.get_height()\n",
    "            ax.annotate(f'{height:.2f}%',\n",
    "                        xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                        xytext=(0, 3),  # 3 points vertical offset\n",
    "                        textcoords=\"offset points\",\n",
    "                        ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "    autolabel(rects1)\n",
    "    autolabel(rects2)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n",
    "    print(f\"Comparison plot saved to {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "31866fae-d790-4bfa-8ee9-4066f3d4f84a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison plot saved to plots/model_comparison.png\n"
     ]
    }
   ],
   "source": [
    "plot_model_comparison(test_acc_domain_lstm, test_acc_domain_bert, test_acc_sub_lstm, test_acc_sub_bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "90d5e6db-5393-4b4e-adf2-7dbe5e61a445",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Confusion Matrix\n",
    "def plot_confusion_matrix(model, data_loader, title, save_dir=\"plots\"):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    model.eval()\n",
    "    \n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            # Handle different batch structures\n",
    "            # LSTM: [X, Y_domain, Y_sub] -> inputs=batch[0], target depends on output_dim\n",
    "            # BERT: [ids, mask, labels] -> inputs=batch[0], mask=batch[1], labels=batch[2]\n",
    "            \n",
    "            if len(batch) == 3 and isinstance(model, BERTClassifier):\n",
    "                input_ids = batch[0].to(model.device)\n",
    "                mask = batch[1].to(model.device)\n",
    "                labels = batch[2].to(model.device)\n",
    "                outputs = model(input_ids, mask)\n",
    "            else:\n",
    "                inputs = batch[0].to(model.device)\n",
    "                # Infer label index: if output_dim is 7, use batch[1], else batch[2]\n",
    "                if model.output_dim == 7:\n",
    "                    labels = batch[1].to(model.device)\n",
    "                else:\n",
    "                    labels = batch[2].to(model.device)\n",
    "                outputs = model(inputs)\n",
    "\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # Create Matrix\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    \n",
    "    # Plot\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax)\n",
    "    ax.set_xlabel('Predicted Label')\n",
    "    ax.set_ylabel('True Label')\n",
    "    ax.set_title(title)\n",
    "    \n",
    "    clean_title = title.replace(\" \", \"_\")\n",
    "    fig.savefig(os.path.join(save_dir, f\"{clean_title}.png\"), bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "    print(f\"Saved confusion matrix: {clean_title}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8cb728b5-b908-4ab7-8eae-584192984447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating confusion matrix for LSTM_Domain_Confusion_Matrix...\n",
      "Saved confusion matrix: LSTM_Domain_Confusion_Matrix.png\n",
      "Generating confusion matrix for LSTM_Sub_Confusion_Matrix...\n",
      "Saved confusion matrix: LSTM_Sub_Confusion_Matrix.png\n",
      "Generating confusion matrix for BERT_Domain_Confusion_Matrix...\n",
      "Saved confusion matrix: BERT_Domain_Confusion_Matrix.png\n",
      "Generating confusion matrix for BERT_Sub_Confusion_Matrix...\n",
      "Saved confusion matrix: BERT_Sub_Confusion_Matrix.png\n"
     ]
    }
   ],
   "source": [
    "plot_confusion_matrix(lstm_domain, val_loader, \"LSTM_Domain_Confusion_Matrix\")\n",
    "plot_confusion_matrix(lstm_sub, val_loader, \"LSTM_Sub_Confusion_Matrix\")\n",
    "\n",
    "plot_confusion_matrix(bert_domain_model, bert_domain_val_ldr, \"BERT_Domain_Confusion_Matrix\")\n",
    "plot_confusion_matrix(bert_sub_model, bert_sub_val_ldr, \"BERT_Sub_Confusion_Matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "42f05a87-ce66-4df0-84af-a5833f5b5fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_class_distribution(y_data, title, save_dir=\"plots\"):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    counts = Counter(y_data)\n",
    "    # Sort by class ID\n",
    "    labels, values = zip(*sorted(counts.items()))\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    ax.bar(labels, values, color='skyblue', edgecolor='black')\n",
    "    \n",
    "    ax.set_xlabel('Class ID')\n",
    "    ax.set_ylabel('Number of Samples')\n",
    "    ax.set_title(title)\n",
    "    ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    clean_title = title.replace(\" \", \"_\")\n",
    "    fig.savefig(os.path.join(save_dir, f\"{clean_title}.png\"), bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "    print(f\"Saved distribution plot: {clean_title}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1effb6ca-3b88-4dec-8bf5-0f1a82207b5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved distribution plot: Domain_Class_Distribution.png\n",
      "Saved distribution plot: Subfield_Class_Distribution.png\n"
     ]
    }
   ],
   "source": [
    "plot_class_distribution(y_domain_raw, \"Domain_Class_Distribution\")\n",
    "plot_class_distribution(y_sub_raw, \"Subfield_Class_Distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "796b47b2-7244-4512-832e-e8460b28195d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_length_vs_accuracy(model, data_loader, model_type=\"LSTM\", bins=5, save_dir=\"plots\"):\n",
    "    model.eval()\n",
    "    correct_by_len = [] # Stores tuple (length, is_correct)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            # FIX: Check if \"BERT\" is part of the string (e.g., \"BERT_Domain\")\n",
    "            if \"BERT\" in model_type:\n",
    "                input_ids = batch[0].to(model.device)\n",
    "                mask = batch[1].to(model.device)\n",
    "                labels = batch[2].to(model.device)\n",
    "                \n",
    "                outputs = model(input_ids, mask)\n",
    "                # Length = sum of attention mask (1s)\n",
    "                lengths = mask.sum(dim=1).cpu().numpy()\n",
    "            else:\n",
    "                inputs = batch[0].to(model.device)\n",
    "                \n",
    "                # Check output dimension to pick correct label from the batch\n",
    "                # (Batch structure: [X, Y_domain, Y_sub])\n",
    "                # If model has 7 outputs, use Y_domain (index 1), else Y_sub (index 2)\n",
    "                if hasattr(model, 'output_dim') and model.output_dim == 7:\n",
    "                    target_idx = 1\n",
    "                else:\n",
    "                    target_idx = 2\n",
    "                    \n",
    "                labels = batch[target_idx].to(model.device)\n",
    "                \n",
    "                outputs = model(inputs)\n",
    "                # Length = count of non-padding tokens (assume 0 is pad)\n",
    "                lengths = (inputs != 0).sum(dim=1).cpu().numpy()\n",
    "                \n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            is_correct = (preds == labels).cpu().numpy()\n",
    "            \n",
    "            for l, c in zip(lengths, is_correct):\n",
    "                correct_by_len.append((l, c))\n",
    "\n",
    "    # Convert to dataframe for easy binning\n",
    "    df = pd.DataFrame(correct_by_len, columns=[\"Length\", \"Correct\"])\n",
    "    \n",
    "    # Create bins\n",
    "    df['Bin'] = pd.cut(df['Length'], bins=bins)\n",
    "    \n",
    "    # Calculate accuracy per bin\n",
    "    summary = df.groupby('Bin')['Correct'].mean()\n",
    "    \n",
    "    # Plot\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    summary.plot(kind='bar', ax=ax, color='teal', alpha=0.7)\n",
    "    \n",
    "    ax.set_title(f'{model_type} Accuracy by Sequence Length')\n",
    "    ax.set_ylabel('Accuracy')\n",
    "    ax.set_xlabel('Sequence Length Range')\n",
    "    ax.set_ylim(0, 1.0)\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    filename = f\"{model_type}_Length_vs_Acc.png\"\n",
    "    fig.savefig(os.path.join(save_dir, filename), bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "    print(f\"Saved length analysis: {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b117661d-b962-4490-adcf-9a5f8e11617c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved length analysis: LSTM_Domain_Length_vs_Acc.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5442/532821707.py:46: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  summary = df.groupby('Bin')['Correct'].mean()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved length analysis: BERT_Domain_Length_vs_Acc.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5442/532821707.py:46: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  summary = df.groupby('Bin')['Correct'].mean()\n"
     ]
    }
   ],
   "source": [
    "# Run for both (using Domain task as the example)\n",
    "plot_length_vs_accuracy(lstm_domain, val_loader, model_type=\"LSTM_Domain\")\n",
    "plot_length_vs_accuracy(bert_domain_model, bert_domain_val_ldr, model_type=\"BERT_Domain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1ff1e85b-a6b3-4eda-862f-48d96c0582b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_worst_mistakes(model, data_loader, tokenizer, raw_texts, indices, k=3):\n",
    "    \"\"\"\n",
    "    Finds the top k most confident errors.\n",
    "    Requires raw_texts and indices to map back to original string.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    errors = [] # (confidence, pred, true, text_idx)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        batch_start_idx = 0\n",
    "        for batch in data_loader:\n",
    "            if isinstance(model, BERTClassifier):\n",
    "                input_ids = batch[0].to(model.device)\n",
    "                mask = batch[1].to(model.device)\n",
    "                labels = batch[2].to(model.device)\n",
    "                outputs = model(input_ids, mask)\n",
    "            else:\n",
    "                inputs = batch[0].to(model.device)\n",
    "                labels = batch[1].to(model.device) # Assuming domain task\n",
    "                outputs = model(inputs)\n",
    "            \n",
    "            probs = F.softmax(outputs, dim=1)\n",
    "            confidences, preds = torch.max(probs, dim=1)\n",
    "            \n",
    "            # Find errors\n",
    "            incorrect_mask = preds != labels\n",
    "            \n",
    "            if incorrect_mask.any():\n",
    "                # Get indices of errors in this batch\n",
    "                batch_err_indices = torch.nonzero(incorrect_mask).squeeze()\n",
    "                if batch_err_indices.dim() == 0: batch_err_indices = batch_err_indices.unsqueeze(0)\n",
    "                \n",
    "                for idx in batch_err_indices:\n",
    "                    global_idx = indices[batch_start_idx + idx.item()]\n",
    "                    conf = confidences[idx].item()\n",
    "                    p = preds[idx].item()\n",
    "                    t = labels[idx].item()\n",
    "                    errors.append((conf, p, t, global_idx))\n",
    "            \n",
    "            batch_start_idx += labels.size(0)\n",
    "\n",
    "    # Sort by confidence (descending)\n",
    "    errors.sort(key=lambda x: x[0], reverse=True)\n",
    "    \n",
    "    print(f\"\\n--- Top {k} Confident Failures for {model.__class__.__name__} ---\")\n",
    "    for i in range(min(k, len(errors))):\n",
    "        conf, p, t, text_idx = errors[i]\n",
    "        print(f\"Confidence: {conf*100:.2f}% | Pred: {p} | True: {t}\")\n",
    "        print(f\"Text snippet: {raw_texts[text_idx][:200]}...\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b29ee367-ad17-451c-ba1d-b42a7ca68efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Top 3 Confident Failures for BERTClassifier ---\n",
      "Confidence: 98.89% | Pred: 4 | True: 0\n",
      "Text snippet: ultraviolet spectrophotometry has been widely applied in determination of water quality parameters because of its advantagous properties compared to chemical method such as high efficiency easy operat...\n",
      "\n",
      "Confidence: 98.85% | Pred: 4 | True: 0\n",
      "Text snippet: object detection and classification have countless applications in human robot interacting systems it is a necessary skill for autonomous robots that perform tasks in household scenarios despite the g...\n",
      "\n",
      "Confidence: 98.76% | Pred: 3 | True: 4\n",
      "Text snippet: longitudinal dispersion coefficient can be determined by experimental procedures in natural streams many theoretical and empirical equations that are based on hydraulic and geometric characteristics h...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Need to pass the dataset indices to map back to raw text\n",
    "# Example for BERT Domain model\n",
    "print_worst_mistakes(bert_domain_model, bert_domain_val_ldr, bert_tokenizer, all_texts, val_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e20d7bbe-d245-41c6-8fcc-a01e88960d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "def plot_tsne(model, data_loader, title, max_samples=1000, save_dir=\"plots\"):\n",
    "    \"\"\"\n",
    "    Runs t-SNE on the features just before the classification layer.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    features = []\n",
    "    labels = []\n",
    "    \n",
    "    # Register a hook to capture the input to the final fully connected layer\n",
    "    # This works for both your LSTM (self.fc) and BERT (self.fc) without changing class code\n",
    "    captured_feats = []\n",
    "    def hook_fn(module, input, output):\n",
    "        # input is a tuple, we want the first element\n",
    "        captured_feats.append(input[0].detach().cpu())\n",
    "\n",
    "    handle = model.fc.register_forward_hook(hook_fn)\n",
    "\n",
    "    print(f\"Collecting features for {title} (limit {max_samples} samples)...\")\n",
    "    \n",
    "    try:\n",
    "        with torch.no_grad():\n",
    "            count = 0\n",
    "            for batch in data_loader:\n",
    "                if count >= max_samples:\n",
    "                    break\n",
    "                \n",
    "                # Standard BERT vs LSTM batch handling\n",
    "                if isinstance(model, BERTClassifier):\n",
    "                    input_ids = batch[0].to(model.device)\n",
    "                    mask = batch[1].to(model.device)\n",
    "                    batch_labels = batch[2].to(model.device)\n",
    "                    model(input_ids, mask) # Forward pass triggers the hook\n",
    "                else:\n",
    "                    inputs = batch[0].to(model.device)\n",
    "                    target_idx = 1 if model.output_dim == 7 else 2\n",
    "                    batch_labels = batch[target_idx].to(model.device)\n",
    "                    model(inputs) # Forward pass triggers the hook\n",
    "\n",
    "                labels.extend(batch_labels.cpu().numpy())\n",
    "                count += inputs.size(0) if not isinstance(model, BERTClassifier) else input_ids.size(0)\n",
    "                \n",
    "    finally:\n",
    "        handle.remove() # Clean up the hook so it doesn't slow down future runs\n",
    "\n",
    "    # Concatenate all features\n",
    "    X = torch.cat(captured_feats, dim=0).numpy()[:len(labels)]\n",
    "    y = np.array(labels)\n",
    "\n",
    "    # Run t-SNE\n",
    "    print(\"Running t-SNE (this might take a moment)...\")\n",
    "    tsne = TSNE(n_components=2, random_state=42, perplexity=30)\n",
    "    X_2d = tsne.fit_transform(X)\n",
    "    \n",
    "    # Plotting\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    unique_labels = np.unique(y)\n",
    "    colors = cm.rainbow(np.linspace(0, 1, len(unique_labels)))\n",
    "    \n",
    "    for label, color in zip(unique_labels, colors):\n",
    "        indices = y == label\n",
    "        plt.scatter(X_2d[indices, 0], X_2d[indices, 1], c=[color], label=f'Class {label}', alpha=0.6, s=10)\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.title(f\"t-SNE of {title} Representations\")\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    clean_title = title.replace(\" \", \"_\")\n",
    "    plt.savefig(os.path.join(save_dir, f\"{clean_title}_tSNE.png\"), bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"Saved t-SNE plot to {save_dir}/{clean_title}_tSNE.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "13da5c38-603f-4d27-a7fb-6e44caf12674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting features for BERT Domain (limit 1000 samples)...\n",
      "Running t-SNE (this might take a moment)...\n",
      "Saved t-SNE plot to plots/BERT_Domain_tSNE.png\n",
      "Collecting features for LSTM Domain (limit 1000 samples)...\n",
      "Running t-SNE (this might take a moment)...\n",
      "Saved t-SNE plot to plots/LSTM_Domain_tSNE.png\n"
     ]
    }
   ],
   "source": [
    "# Run on Domain task (most distinct classes)\n",
    "plot_tsne(bert_domain_model, bert_domain_val_ldr, \"BERT Domain\")\n",
    "plot_tsne(lstm_domain, val_loader, \"LSTM Domain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4512e101-16cc-49fb-8d78-819ca30b9b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confidence_hist(model, data_loader, title, save_dir=\"plots\"):\n",
    "    model.eval()\n",
    "    confidences = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            if isinstance(model, BERTClassifier):\n",
    "                inputs, mask = batch[0].to(model.device), batch[1].to(model.device)\n",
    "                outputs = model(inputs, mask)\n",
    "            else:\n",
    "                inputs = batch[0].to(model.device)\n",
    "                outputs = model(inputs)\n",
    "            \n",
    "            # Apply Softmax to get probabilities (0 to 1)\n",
    "            probs = F.softmax(outputs, dim=1)\n",
    "            \n",
    "            # Get the probability of the predicted class (the max prob)\n",
    "            max_probs, _ = torch.max(probs, dim=1)\n",
    "            confidences.extend(max_probs.cpu().numpy())\n",
    "            \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.hist(confidences, bins=20, range=(0,1), color='purple', alpha=0.7, edgecolor='black')\n",
    "    plt.xlabel('Prediction Confidence (Probability)')\n",
    "    plt.ylabel('Count')\n",
    "    plt.title(f'{title} Confidence Distribution')\n",
    "    plt.grid(axis='y', alpha=0.5)\n",
    "    \n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    clean_title = title.replace(\" \", \"_\")\n",
    "    plt.savefig(os.path.join(save_dir, f\"{clean_title}_Confidence.png\"))\n",
    "    plt.close()\n",
    "    print(f\"Saved confidence plot: {clean_title}_Confidence.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "41a3c97f-04a2-4db7-bc50-1b9adf3c0b4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved confidence plot: BERT_Domain_Confidence.png\n",
      "Saved confidence plot: LSTM_Domain_Confidence.png\n"
     ]
    }
   ],
   "source": [
    "plot_confidence_hist(bert_domain_model, bert_domain_val_ldr, \"BERT Domain\")\n",
    "plot_confidence_hist(lstm_domain, val_loader, \"LSTM Domain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a840e10b-3fc9-4830-9bb2-913e18c7942b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
